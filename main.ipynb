{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stunning-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210223 20:27:09 train:47] args: Namespace(B=64, H=100, T=10, a_dim=6, data_dir='./data/', depth=0, device=[0], epochs=20, h_dim=128, iters_to_accumulate=1, load_epoch=None, o_dim=17, s_dim=64, seed=0, timestamp='Feb23_20-27-09')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "(900, 100, 6) (900, 100, 17)\n",
      "(100, 100, 6) (100, 100, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210223 20:27:12 trainer:53] (train) Epoch: 1 {'s_loss': 30850646.13392857, 'x_loss': 285.2186791556222, 's_aux_loss': 56.47733579363142, 'loss': 30850932.01785714}\n",
      "[I 210223 20:27:12 trainer:53] (test) Epoch: 1 {'s_loss': 201723.515625, 'x_loss': 238.38076782226562, 's_aux_loss': 47.83351135253906, 'loss': 201961.890625}\n",
      "[I 210223 20:27:13 trainer:53] (train) Epoch: 2 {'s_loss': 100746.994140625, 'x_loss': 258.872193472726, 's_aux_loss': 42.69347218104771, 'loss': 101005.86607142857}\n",
      "[I 210223 20:27:13 trainer:53] (test) Epoch: 2 {'s_loss': 39650.51171875, 'x_loss': 215.9703826904297, 's_aux_loss': 36.18363571166992, 'loss': 39866.48046875}\n",
      "[I 210223 20:27:14 trainer:53] (train) Epoch: 3 {'s_loss': 25596.91476004464, 'x_loss': 247.93915448869978, 's_aux_loss': 33.75431292397635, 'loss': 25844.854352678572}\n",
      "[I 210223 20:27:14 trainer:53] (test) Epoch: 3 {'s_loss': 15465.57421875, 'x_loss': 207.56192016601562, 's_aux_loss': 30.281095504760742, 'loss': 15673.1357421875}\n",
      "[I 210223 20:27:15 trainer:53] (train) Epoch: 4 {'s_loss': 11632.500279017857, 'x_loss': 245.53059714181083, 's_aux_loss': 28.8798337663923, 'loss': 11878.030831473214}\n",
      "[I 210223 20:27:15 trainer:53] (test) Epoch: 4 {'s_loss': 8355.861328125, 'x_loss': 200.7540283203125, 's_aux_loss': 26.32716941833496, 'loss': 8556.615234375}\n",
      "[I 210223 20:27:16 trainer:53] (train) Epoch: 5 {'s_loss': 6673.871198381697, 'x_loss': 240.77288818359375, 's_aux_loss': 25.824268341064453, 'loss': 6914.644008091518}\n",
      "[I 210223 20:27:16 trainer:53] (test) Epoch: 5 {'s_loss': 5435.0029296875, 'x_loss': 192.79006958007812, 's_aux_loss': 24.166505813598633, 'loss': 5627.79296875}\n",
      "[I 210223 20:27:17 trainer:53] (train) Epoch: 6 {'s_loss': 4356.775442940848, 'x_loss': 240.55584389822823, 's_aux_loss': 24.42121151515416, 'loss': 4597.331333705357}\n",
      "[I 210223 20:27:17 trainer:53] (test) Epoch: 6 {'s_loss': 3540.473876953125, 'x_loss': 183.7342529296875, 's_aux_loss': 23.664304733276367, 'loss': 3724.2080078125}\n",
      "[I 210223 20:27:18 trainer:53] (train) Epoch: 7 {'s_loss': 2844.8702218191966, 'x_loss': 236.80347878592355, 's_aux_loss': 24.268358503069198, 'loss': 3081.6736886160716}\n",
      "[I 210223 20:27:18 trainer:53] (test) Epoch: 7 {'s_loss': 2223.720947265625, 'x_loss': 185.47181701660156, 's_aux_loss': 22.938678741455078, 'loss': 2409.19287109375}\n",
      "[I 210223 20:27:19 trainer:53] (train) Epoch: 8 {'s_loss': 1882.8183855329241, 'x_loss': 235.3659885951451, 's_aux_loss': 23.67642320905413, 'loss': 2118.1843697684153}\n",
      "[I 210223 20:27:20 trainer:53] (test) Epoch: 8 {'s_loss': 1558.8951416015625, 'x_loss': 185.33615112304688, 's_aux_loss': 22.46229362487793, 'loss': 1744.2313232421875}\n",
      "[I 210223 20:27:20 trainer:53] (train) Epoch: 9 {'s_loss': 1370.6695731026787, 'x_loss': 236.5281273978097, 's_aux_loss': 23.0390111378261, 'loss': 1607.1976841517858}\n",
      "[I 210223 20:27:21 trainer:53] (test) Epoch: 9 {'s_loss': 1208.6131591796875, 'x_loss': 182.14126586914062, 's_aux_loss': 21.254711151123047, 'loss': 1390.75439453125}\n",
      "[I 210223 20:27:22 trainer:53] (train) Epoch: 10 {'s_loss': 1118.592054094587, 'x_loss': 236.139043535505, 's_aux_loss': 21.61201368059431, 'loss': 1354.7311139787946}\n",
      "[I 210223 20:27:22 trainer:53] (test) Epoch: 10 {'s_loss': 996.3565063476562, 'x_loss': 184.28073120117188, 's_aux_loss': 19.68026351928711, 'loss': 1180.63720703125}\n",
      "[I 210223 20:27:23 trainer:53] (train) Epoch: 11 {'s_loss': 888.4434509277344, 'x_loss': 237.29815237862724, 's_aux_loss': 20.080650329589844, 'loss': 1125.7415945870537}\n",
      "[I 210223 20:27:23 trainer:53] (test) Epoch: 11 {'s_loss': 773.374755859375, 'x_loss': 186.5012664794922, 's_aux_loss': 18.356428146362305, 'loss': 959.8760375976562}\n",
      "[I 210223 20:27:24 trainer:53] (train) Epoch: 12 {'s_loss': 688.63083757673, 'x_loss': 237.94337572370256, 's_aux_loss': 18.371723447527206, 'loss': 926.574214390346}\n",
      "[I 210223 20:27:24 trainer:53] (test) Epoch: 12 {'s_loss': 619.2860107421875, 'x_loss': 188.7008819580078, 's_aux_loss': 17.041820526123047, 'loss': 807.9868774414062}\n",
      "[I 210223 20:27:25 trainer:53] (train) Epoch: 13 {'s_loss': 559.8004804338727, 'x_loss': 240.21455601283483, 's_aux_loss': 17.82821954999651, 'loss': 800.0150364467075}\n",
      "[I 210223 20:27:25 trainer:53] (test) Epoch: 13 {'s_loss': 504.1580505371094, 'x_loss': 191.13238525390625, 's_aux_loss': 17.332117080688477, 'loss': 695.2904052734375}\n",
      "[I 210223 20:27:26 trainer:53] (train) Epoch: 14 {'s_loss': 475.78370448521207, 'x_loss': 239.85135759626115, 's_aux_loss': 18.72926276070731, 'loss': 715.6350620814732}\n",
      "[I 210223 20:27:26 trainer:53] (test) Epoch: 14 {'s_loss': 439.0439147949219, 'x_loss': 188.10104370117188, 's_aux_loss': 18.884672164916992, 'loss': 627.1449584960938}\n",
      "[I 210223 20:27:27 trainer:53] (train) Epoch: 15 {'s_loss': 416.79342215401783, 'x_loss': 239.45762852260046, 's_aux_loss': 20.079898289271764, 'loss': 656.2510463169643}\n",
      "[I 210223 20:27:27 trainer:53] (test) Epoch: 15 {'s_loss': 393.27728271484375, 'x_loss': 190.53929138183594, 's_aux_loss': 20.492633819580078, 'loss': 583.8165893554688}\n",
      "[I 210223 20:27:28 trainer:53] (train) Epoch: 16 {'s_loss': 373.3909824916295, 'x_loss': 239.72848401750838, 's_aux_loss': 22.12475299835205, 'loss': 613.1194719587054}\n",
      "[I 210223 20:27:28 trainer:53] (test) Epoch: 16 {'s_loss': 360.1889343261719, 'x_loss': 185.38595581054688, 's_aux_loss': 22.235795974731445, 'loss': 545.5748901367188}\n",
      "[I 210223 20:27:29 trainer:53] (train) Epoch: 17 {'s_loss': 344.1447296142578, 'x_loss': 239.9020233154297, 's_aux_loss': 23.96413721357073, 'loss': 584.0467485700335}\n",
      "[I 210223 20:27:29 trainer:53] (test) Epoch: 17 {'s_loss': 335.982421875, 'x_loss': 193.50070190429688, 's_aux_loss': 25.33694076538086, 'loss': 529.483154296875}\n",
      "[I 210223 20:27:30 trainer:53] (train) Epoch: 18 {'s_loss': 322.97166442871094, 'x_loss': 240.48096793038505, 's_aux_loss': 26.371103150503977, 'loss': 563.452641078404}\n",
      "[I 210223 20:27:30 trainer:53] (test) Epoch: 18 {'s_loss': 319.6011047363281, 'x_loss': 190.18310546875, 's_aux_loss': 27.69414520263672, 'loss': 509.7842102050781}\n",
      "[I 210223 20:27:31 trainer:53] (train) Epoch: 19 {'s_loss': 306.72483607700894, 'x_loss': 239.70714460100447, 's_aux_loss': 28.72524697440011, 'loss': 546.4319719587054}\n",
      "[I 210223 20:27:31 trainer:53] (test) Epoch: 19 {'s_loss': 293.8294372558594, 'x_loss': 189.7320098876953, 's_aux_loss': 29.394445419311523, 'loss': 483.56146240234375}\n",
      "[I 210223 20:27:32 trainer:53] (train) Epoch: 20 {'s_loss': 289.38038635253906, 'x_loss': 238.77874101911272, 's_aux_loss': 31.241474287850515, 'loss': 528.1591230119977}\n",
      "[I 210223 20:27:32 trainer:53] (test) Epoch: 20 {'s_loss': 284.6401672363281, 'x_loss': 184.2693634033203, 's_aux_loss': 33.4454345703125, 'loss': 468.9095458984375}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"./dssm\")\n",
    "from train import main as train_ssm\n",
    "from diayn.examples.diayn import experiment\n",
    "from rlkit.envs.wrappers import NormalizedBoxEnv\n",
    "from rlkit.samplers.util import DIAYNRollout as rollout\n",
    "\n",
    "\n",
    "def collect(sim, policy, depth, args):\n",
    "    data = []\n",
    "    for skill in range(policy.stochastic_policy.skill_dim):\n",
    "        for trial in tqdm(range(100)):\n",
    "            # print(\"skill-{} rollout-{}\".format(skill, trial))\n",
    "            path = rollout(\n",
    "                sim,\n",
    "                policy,\n",
    "                skill,\n",
    "                max_path_length=args.H,\n",
    "                render=False,\n",
    "            )\n",
    "            data.append([path['actions'], path['next_observations']])\n",
    "\n",
    "    train_data = data[:int(len(data)*0.9)]\n",
    "    test_data = data[int(len(data)*0.9):]\n",
    "\n",
    "    train_path = os.path.join(args.data_dir, \"./train{}.pkl\".format(depth))\n",
    "    test_path = os.path.join(args.data_dir, \"./test{}.pkl\".format(depth))\n",
    "    os.makedirs(args.data_dir, exist_ok=True)\n",
    "    with open(train_path, mode='wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    with open(test_path, mode='wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "\n",
    "\n",
    "def update_sim(sim, depth):\n",
    "    ssm = train_ssm(\"--H {} --depth {}\".format(args.H, depth))\n",
    "    # return Sim(sim)\n",
    "\n",
    "\n",
    "def update_policy():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def Sim(env):\n",
    "    def step(action):\n",
    "        lb = env._wrapped_env.action_space.low\n",
    "        ub = env._wrapped_env.action_space.high\n",
    "        scaled_action = lb + (action + 1.) * 0.5 * (ub - lb)\n",
    "        scaled_action = np.clip(scaled_action, lb, ub)\n",
    "\n",
    "        wrapped_step = env._wrapped_env.step(scaled_action)\n",
    "        next_obs, reward, done, info = wrapped_step\n",
    "        if env._should_normalize:\n",
    "            next_obs = env._apply_normalize_obs(next_obs)\n",
    "        return next_obs, reward * env._reward_scale, done, info\n",
    "\n",
    "    env.step = step\n",
    "    return env\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('env', type=str,\n",
    "                        help='environment')\n",
    "    parser.add_argument('file', type=str,\n",
    "                        help='path to the snapshot file')\n",
    "    parser.add_argument(\"--data_dir\", type=str,\n",
    "                        default=\"./data/\")\n",
    "    parser.add_argument('--skill_dim', type=int, default=10,\n",
    "                        help='skill dimension')\n",
    "    parser.add_argument('--H', type=int, default=300,\n",
    "                        help='Max length of rollout')\n",
    "    parser.add_argument('--D', type=int, default=1,\n",
    "                        help='Depth (The number of update)')\n",
    "    args = parser.parse_args(\"HalfCheetah-v2 diayn/data/DIAYN-10-HalfCheetah-v2/DIAYN_10_HalfCheetah-v2_2021_02_23_11_50_33_0000--s-0/params.pkl --H 100\".split())\n",
    "\n",
    "\n",
    "    data = torch.load(args.file)\n",
    "    policy = data['evaluation/policy']\n",
    "    env = NormalizedBoxEnv(gym.make(str(args.env)))\n",
    "    sim = Sim(NormalizedBoxEnv(gym.make(str(args.env))))\n",
    "\n",
    "    for depth in range(args.D):\n",
    "        collect(sim, policy, depth, args)\n",
    "        sim = update_sim(sim, depth)\n",
    "        #print(data[0].keys(), len(data))\n",
    "        # sim = update_sim(data)\n",
    "        # policy = update_policy(sim, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-batch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
